{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vul Adv Heads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.file_utils import load_files_named\n",
    "\n",
    "output_folder = 'outputs_vul'\n",
    "\n",
    "full_per_head_logit_diffs = load_files_named(output_folder, file_starts_with='full', if_gpu=True)\n",
    "\n",
    "mean_per_head_logit_diffs = torch.mean(torch.stack(full_per_head_logit_diffs), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as pth\n",
    "torch.save(mean_per_head_logit_diffs, f'saved/bias/vul_heads_og_method_bias.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Gradients Toxicicity Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.file_utils import load_pickle_from_gpu\n",
    "\n",
    "folder_path = 'saved/bias'\n",
    "files = ['mean_gradients_-1_300_600.pkl','sample_tokens_-1_300_600.pkl']\n",
    "\n",
    "loaded_files = []\n",
    "\n",
    "for filename in files:\n",
    "    file_path =  f'{folder_path}/{filename}'\n",
    "    loaded_files.append(load_pickle_from_gpu(file_path))\n",
    "\n",
    "grads = loaded_files[0]\n",
    "tokens = loaded_files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token='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')\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    #default_prepend_bos = False\n",
    "    # refactor_factored_attn_matrices=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_score = np.array(grads)\n",
    "emb_score_mean_iter = np.mean(emb_score, axis=(0))  # mean over iterations Shape: [batch,token_length]\n",
    "\n",
    "tokens_example = tokens\n",
    "gradients_example = emb_score_mean_iter\n",
    "\n",
    "# Plotting\n",
    "num_samples = len(tokens_example)\n",
    "fig, axes = plt.subplots(num_samples, 1, figsize=(24, 5 * num_samples), constrained_layout=True)\n",
    "\n",
    "if num_samples == 1:\n",
    "    axes = [axes]  # Ensure axes is always a list for consistent indexing\n",
    "\n",
    "for i, (words, grad) in enumerate(zip(tokens_example, gradients_example)):\n",
    "    words = model.to_string(words.unsqueeze(1))\n",
    "    ax = axes[i]\n",
    "    ax.bar(range(len(words)), grad, color='skyblue')\n",
    "    ax.set_xticks(range(len(words)))\n",
    "    ax.set_xticklabels(words, rotation=45, ha='right', fontsize=12)\n",
    "    ax.set_title(f'Average gradient score over iterations', fontsize=16)\n",
    "    ax.set_ylabel('Gradient Score', fontsize=14)\n",
    "    ax.set_xlabel('Tokens', fontsize=14)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    ax.set_ylim([0, 5])\n",
    "\n",
    "plt.savefig('saved/bias/plot_grad_example_tokens.svg', format='svg')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example boundaries (set these as needed)\n",
    "start_boundary = 33  # Tokens before this index are summed\n",
    "end_boundary = 85    # Tokens after this index are summed\n",
    "start_middle = 36\n",
    "\n",
    "\n",
    "# Gradient scores (replace with your data)\n",
    "emb_score = np.array(grads)\n",
    "emb_score_mean_iter = np.mean(emb_score, axis=(0))  # Mean over iterations Shape: [batch, token_length]\n",
    "\n",
    "tokens_example = tokens[3:4]\n",
    "gradients_example = emb_score_mean_iter[3:4]\n",
    "\n",
    "# Function to process tokens and gradients with boundaries\n",
    "def process_tokens_and_gradients(tokens, gradients, start, end, start_middle):\n",
    "    # Summing scores for tokens outside the boundaries\n",
    "    start_score = np.sum(gradients[:start]) / start\n",
    "    middle_score = np.sum(gradients[start_middle:end+1]) / (end+1-start_middle)\n",
    "    end_score = np.sum(gradients[end+1:]) / (len(gradients) - end - 1)\n",
    "    \n",
    "    # Extract tokens and gradients within the boundary\n",
    "    tokens_in_boundary = tokens[start:start_middle-1]\n",
    "    tokens_in_boundary = model.to_string(tokens_in_boundary.unsqueeze(1))\n",
    "    gradients_in_boundary = gradients[start:start_middle-1]\n",
    "    # Add special tokens for the start and end sums\n",
    "    tokens_in_boundary = [\"instruction tokens\"] + tokens_in_boundary + [\"sentence tokens\"] + [\"padding tokens\"]\n",
    "    gradients_in_boundary = [start_score] + list(gradients_in_boundary) + [middle_score] + [end_score]\n",
    "    \n",
    "    return tokens_in_boundary, gradients_in_boundary\n",
    "\n",
    "# Process tokens and gradients\n",
    "processed_tokens = []\n",
    "processed_gradients = []\n",
    "\n",
    "for words, grad in zip(tokens_example, gradients_example):\n",
    "    processed_words, processed_grads = process_tokens_and_gradients(words, grad, start_boundary, end_boundary, start_middle)\n",
    "    processed_tokens.append(processed_words)\n",
    "    processed_gradients.append(processed_grads)\n",
    "\n",
    "# Plotting\n",
    "num_samples = len(processed_tokens)\n",
    "fig, axes = plt.subplots(num_samples, 1, figsize=(15, 5 * num_samples), constrained_layout=True)\n",
    "\n",
    "if num_samples == 1:\n",
    "    axes = [axes]  # Ensure axes is always a list for consistent indexing\n",
    "\n",
    "for i, (words, grad) in enumerate(zip(processed_tokens, processed_gradients)):\n",
    "    ax = axes[i]\n",
    "    ax.bar(range(len(words)), grad, color='skyblue')\n",
    "    ax.set_xticks(range(len(words)))\n",
    "    ax.set_xticklabels(words, rotation=45, ha='right', fontsize=12)\n",
    "    ax.set_title(f'Average gradient score over iterations', fontsize=16)\n",
    "    ax.set_ylabel('Gradient Score', fontsize=14)\n",
    "    ax.set_xlabel('Tokens', fontsize=14)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    ax.set_ylim([0, 2])\n",
    "\n",
    "plt.savefig(\"plot_ferrari.svg\", format=\"svg\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean/Max Gradients OG Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'saved/acronym'\n",
    "files = ['full_masked_maxs.pickle','full_masked_means.pickle','full_unmasked_maxs.pickle','full_unmasked_means.pickle']\n",
    "\n",
    "loaded_files = []\n",
    "\n",
    "for filename in files:\n",
    "    with open(f'{folder_path}/{filename}', 'rb') as f:\n",
    "\n",
    "            loaded_files.append(pickle.load(f))\n",
    "\n",
    "full_masked_maxs = loaded_files[0]\n",
    "full_unmasked_maxs = loaded_files[2]\n",
    "full_masked_means = loaded_files[1]\n",
    "full_unmasked_means = loaded_files[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_masked_maxs_np = np.array(full_masked_maxs)\n",
    "full_unmasked_maxs_np = np.array(full_unmasked_maxs)\n",
    "\n",
    "# Compute mean and standard deviation over trials (axis 0)\n",
    "masked_mean = np.mean(full_masked_maxs_np, axis=0)\n",
    "masked_std = np.std(full_masked_maxs_np, axis=0)\n",
    "\n",
    "unmasked_mean = np.mean(full_unmasked_maxs_np, axis=0)\n",
    "unmasked_std = np.std(full_unmasked_maxs_np, axis=0)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Masked plot with mean and std\n",
    "plt.plot(range(full_masked_maxs_np.shape[1]), masked_mean, label=\"Masked Mean\", color=\"red\")\n",
    "plt.fill_between(\n",
    "    range(full_masked_maxs_np.shape[1]),\n",
    "    masked_mean - masked_std,\n",
    "    masked_mean + masked_std,\n",
    "    color=\"red\",\n",
    "    alpha=0.2,\n",
    "    label=\"Masked Std Dev\"\n",
    ")\n",
    "\n",
    "# Unmasked plot with mean and std\n",
    "plt.plot(range(full_unmasked_maxs_np.shape[1]), unmasked_mean, label=\"Unmasked Mean\", color=\"blue\")\n",
    "plt.fill_between(\n",
    "    range(full_unmasked_maxs_np.shape[1]),\n",
    "    unmasked_mean - unmasked_std,\n",
    "    unmasked_mean + unmasked_std,\n",
    "    color=\"blue\",\n",
    "    alpha=0.2,\n",
    "    label=\"Unmasked Std Dev\"\n",
    ")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0, 12])\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Normalized Gradient Score\")\n",
    "plt.title(\"Absolute Max of Tokens Gradient Score in a sentence per Iterations (over many trials)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_masked_mean = np.array(full_masked_means)\n",
    "full_unmasked_mean = np.array(full_unmasked_means)\n",
    "\n",
    "# Compute mean and standard deviation over trials (axis 0)\n",
    "masked_mean = np.mean(full_masked_mean, axis=0)\n",
    "masked_std = np.std(full_masked_mean, axis=0)\n",
    "\n",
    "unmasked_mean = np.mean(full_unmasked_mean, axis=0)\n",
    "unmasked_std = np.std(full_unmasked_mean, axis=0)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Masked plot with mean and std\n",
    "plt.plot(range(full_masked_mean.shape[1]), masked_mean, label=\"Masked Mean\", color=\"red\")\n",
    "plt.fill_between(\n",
    "    range(full_masked_mean.shape[1]),\n",
    "    masked_mean - masked_std,\n",
    "    masked_mean + masked_std,\n",
    "    color=\"red\",\n",
    "    alpha=0.2,\n",
    "    label=\"Masked Std Dev\"\n",
    ")\n",
    "\n",
    "# Unmasked plot with mean and std\n",
    "plt.plot(range(full_unmasked_mean.shape[1]), unmasked_mean, label=\"Unmasked Mean\", color=\"blue\")\n",
    "plt.fill_between(\n",
    "    range(full_unmasked_mean.shape[1]),\n",
    "    unmasked_mean - unmasked_std,\n",
    "    unmasked_mean + unmasked_std,\n",
    "    color=\"blue\",\n",
    "    alpha=0.2,\n",
    "    label=\"Unmasked Std Dev\"\n",
    ")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0, 3])\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Normalized Gradient Score\")\n",
    "plt.title(\"Mean of Tokens Gradient Score in a sentence per Iterations (over many trials)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
