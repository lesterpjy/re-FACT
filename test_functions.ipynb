{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.8146, -0.3438, -1.1104],\n",
      "        [ 0.3662, -0.3272, -1.1627],\n",
      "        [ 0.9963,  1.1391,  0.0909],\n",
      "        [-1.7906, -1.0357,  0.9291],\n",
      "        [-0.0374, -1.8921,  0.1530],\n",
      "        [ 0.3227,  0.9455,  1.0787]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "embed = torch.nn.Embedding(6, 3)\n",
    "\n",
    "# 10 words in the vocabulary, 3 dimensional embeddings\n",
    "print(embed.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = torch.tensor([[1, 4, 5], [4, 3, 2]])\n",
    "\n",
    "embedded_sentence = embed(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "token_list = torch.tensor([1, 2, 3, 4], dtype=torch.long)\n",
    "\n",
    "print(token_list[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([4, 2])\n",
      "tensor([[1.],\n",
      "        [7.],\n",
      "        [7.],\n",
      "        [7.]])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = torch.tensor([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]], [[7, 8, 9], [10, 11, 12]], [[7, 8, 9], [10, 11, 12]]], dtype=torch.float32)\n",
    "vocab_embeddings = torch.tensor([[1, 0, 0], [0,0,1]], dtype=torch.float32)\n",
    "\n",
    "print(input_embeddings.shape)\n",
    "print(vocab_embeddings.shape)\n",
    "\n",
    "dot = torch.einsum('ntd,td->nt', input_embeddings, vocab_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test FlexVocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.adv_sample.vocab import *\n",
    "import logging\n",
    "#set logger \n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:src.adv_sample.vocab:FlexibleVocab: __init__(): initialized with 5 words/phrases\n",
      "DEBUG:src.adv_sample.vocab:FlexibleVocab: compare_strict(): input_embeddings shape: torch.Size([2, 5])\n",
      "DEBUG:src.adv_sample.vocab:FlexibleVocab: compare_strict(): vocab_embeddings shape: torch.Size([3, 2, 5])\n",
      "DEBUG:src.adv_sample.vocab:FlexibleVocab: compare_strict(): dot_products shape: torch.Size([3])\n",
      "DEBUG:src.adv_sample.vocab:FlexibleVocab: compare_strict_batch(): dot_products shape: torch.Size([2, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized list: [[0], [1], [2, 3], [4, 5], [6, 7]]\n",
      "Input tokens: [2, 3] (New York)\n",
      "Similarities: tensor([10.9933, -2.2089, -3.1947])\n",
      "Token list: [(2, 3), (4, 5), (6, 7)]\n",
      "Token list (string): [['New', 'York'], ['Los', 'Angeles'], ['San', 'Francisco']]\n",
      "Input tokens (batch): [[2, 3], [2, 1]] (New York, New world)\n",
      "Batch similarities: tensor([[10.9933, -2.2089, -3.1947],\n",
      "        [ 4.5514, -3.9152, -1.1237]])\n",
      "Token list: [(2, 3), (4, 5), (6, 7)]\n",
      "Token list (string): [['New', 'York'], ['Los', 'Angeles'], ['San', 'Francisco']]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/dl2024/lib/python3.12/site-packages (from sentence-transformers) (4.66.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/envs/dl2024/lib/python3.12/site-packages (from sentence-transformers) (2.2.2)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-macosx_10_13_x86_64.whl.metadata (31 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.15.1-cp312-cp312-macosx_10_13_x86_64.whl.metadata (61 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/envs/dl2024/lib/python3.12/site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/dl2024/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/dl2024/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/envs/dl2024/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/dl2024/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/dl2024/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/dl2024/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/dl2024/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/dl2024/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/dl2024/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/dl2024/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-macosx_10_13_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-macosx_10_12_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/dl2024/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/dl2024/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/dl2024/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/dl2024/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/dl2024/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/dl2024/lib/python3.12/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Downloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "Downloading transformers-4.48.0-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.6.1-cp312-cp312-macosx_10_13_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.1-cp312-cp312-macosx_10_13_x86_64.whl (41.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-macosx_10_13_x86_64.whl (288 kB)\n",
      "Downloading safetensors-0.5.2-cp38-abi3-macosx_10_12_x86_64.whl (427 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-macosx_10_12_x86_64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: threadpoolctl, scipy, safetensors, regex, joblib, scikit-learn, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed huggingface-hub-0.27.1 joblib-1.4.2 regex-2024.11.6 safetensors-0.5.2 scikit-learn-1.6.1 scipy-1.15.1 sentence-transformers-3.3.1 threadpoolctl-3.5.0 tokenizers-0.21.0 transformers-4.48.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.util import semantic_search\n",
    "#this will work when we have single embeddings for each sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 1\n",
    "query_embedding = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "torch.Size([4, 8])\n",
      "tensor(1)\n",
      "torch.Size([4, 8])\n",
      "tensor(2)\n",
      "torch.Size([2, 8])\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
      "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "         [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example data\n",
    "mask = torch.tensor([[0, 1, 0, 2, 2], [0, 1, 0, 1, 1]])  # Shape: [batch, sentence length]\n",
    "batch_emb = torch.rand(2, 5, 8)  # Shape: [batch, sentence length, emb dim]\n",
    "\n",
    "batch_emb_old = batch_emb.clone()\n",
    "# Example perturbation function\n",
    "def function_x(embeddings,x):\n",
    "    return embeddings + x*0.1  # Adds 0.1 to all embeddings as a simple example\n",
    "\n",
    "# Iterate over unique values in mask\n",
    "for i in torch.unique(mask):\n",
    "    # Get the indices where mask == i\n",
    "    indices = mask == i\n",
    "\n",
    "    # Expand indices to match the embedding dimensions\n",
    "    expanded_indices = indices.unsqueeze(-1).expand_as(batch_emb)\n",
    "\n",
    "    # Select embeddings where mask == i\n",
    "    selected_embeddings = batch_emb[expanded_indices].view(-1, batch_emb.size(-1))\n",
    "\n",
    "    # Apply the perturbation function\n",
    "    perturbed_embeddings = function_x(selected_embeddings, i)\n",
    "    print(i)\n",
    "    print(perturbed_embeddings.shape)\n",
    "    # Update the embeddings in batch_emb\n",
    "    batch_emb[expanded_indices] = perturbed_embeddings.view(-1)\n",
    "\n",
    "# Output updated batch_emb\n",
    "print(batch_emb-batch_emb_old)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.adv_sample.vocab import FlexibleVocab\n",
    "from src.adv_sample.projection import *\n",
    "import logging\n",
    "#set logger \n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:src.adv_sample.vocab:FlexibleVocab: __init__(): initialized with 5 words/phrases\n",
      "/var/folders/2q/z8df08fx73b3vq941pty77xh0000gn/T/ipykernel_48442/788928216.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample_tokens = torch.tensor(tokenized_sentences),\n",
      "DEBUG:src.adv_sample.projection:project_embeddings: batch_emb.shape: torch.Size([2, 4, 5])\n",
      "DEBUG:src.adv_sample.projection:project_embeddings: i: 2\n",
      "DEBUG:src.adv_sample.projection:project_embeddings: expanded_indices.shape: torch.Size([2, 4, 5])\n",
      "DEBUG:src.adv_sample.vocab:FlexibleVocab: compare_strict_batch(): dot_products shape: torch.Size([4, 3])\n",
      "DEBUG:src.adv_sample.projection:project_embeddings: embedding_closest.shape: torch.Size([40])\n",
      "DEBUG:src.adv_sample.projection:project_embeddings: batch_emb[expanded_indices] shape: torch.Size([40])\n",
      "DEBUG:src.adv_sample.projection:project_embeddings: batch_emb.shape: torch.Size([2, 4, 5])\n",
      "DEBUG:src.adv_sample.projection:project_embeddings: batch_tokens.shape: torch.Size([2, 4])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized list: [[0], [1], [2, 3], [4, 5], [6, 7]]\n",
      "Sentences: [['hello world New York'], ['Los Angeles San Francisco']]\n",
      "Tokenized sentences: tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]])\n",
      "Embedded sentences shape: torch.Size([2, 4, 5])\n",
      "embedding_matrix: tensor([[ 0.0153, -0.4999, -0.3092,  0.7763,  0.4409],\n",
      "        [ 1.1743, -0.6821, -0.1023, -0.8058,  1.2322],\n",
      "        [-1.6690, -0.9466,  1.6276, -0.4205,  1.0767],\n",
      "        [-0.1436,  0.7899,  1.3661, -0.3493, -0.0877],\n",
      "        [ 0.3316,  0.4878,  0.3246,  0.0042, -0.0951],\n",
      "        [-1.0491,  0.0913, -0.2221,  1.3203,  0.0719],\n",
      "        [-1.6340, -0.0591, -0.5550, -0.6465, -2.0284],\n",
      "        [-1.6568,  0.0786, -0.7852, -0.5429, -1.2553]])\n",
      "Batch tokens: tensor([[2, 3, 2, 3],\n",
      "        [4, 5, 6, 7]])\n",
      "Batch embeddings: tensor([[[-1.6690, -0.9466,  1.6276, -0.4205,  1.0767],\n",
      "         [-0.1436,  0.7899,  1.3661, -0.3493, -0.0877],\n",
      "         [-1.6690, -0.9466,  1.6276, -0.4205,  1.0767],\n",
      "         [-0.1436,  0.7899,  1.3661, -0.3493, -0.0877]],\n",
      "\n",
      "        [[ 0.3316,  0.4878,  0.3246,  0.0042, -0.0951],\n",
      "         [-1.0491,  0.0913, -0.2221,  1.3203,  0.0719],\n",
      "         [-1.6340, -0.0591, -0.5550, -0.6465, -2.0284],\n",
      "         [-1.6568,  0.0786, -0.7852, -0.5429, -1.2553]]])\n"
     ]
    }
   ],
   "source": [
    "# Dummy embedding matrix (8 tokens, 5 dimensions)\n",
    "embedding_matrix = torch.randn(8, 5)\n",
    "\n",
    "# Tokenized vocabulary (words/phrases)\n",
    "vocab_string = [[\"hello\"], [\"world\"], [\"New\", \"York\"], [\"Los\", \"Angeles\"], [\"San\", \"Francisco\"]]\n",
    "words_to_ids = {\"hello\": 0, \"world\": 1, \"New\": 2, \"York\": 3, \"Los\": 4, \"Angeles\": 5, \"San\": 6, \"Francisco\": 7}\n",
    "ids_to_words = {v: k for k, v in words_to_ids.items()}\n",
    "\n",
    "vocab_tokens = [[words_to_ids[word] for word in token] for token in vocab_string]\n",
    "\n",
    "print(\"Tokenized list:\", vocab_tokens)\n",
    "\n",
    "# Create FlexibleVocab object\n",
    "flex_vocab = FlexibleVocab(vocab_tokens, embedding_matrix)\n",
    "\n",
    "sentences = [[\"hello world New York\"], [\"Los Angeles San Francisco\"]]\n",
    "print(f\"Sentences: {sentences}\")\n",
    "tokenized_sentences = torch.tensor([[words_to_ids[word] for word in sentence[0].split()] for sentence in sentences])\n",
    "print(f\"Tokenized sentences: {tokenized_sentences}\")\n",
    "embedded_sentences = flex_vocab.embedding_matrix[tokenized_sentences.view(-1)].view(tokenized_sentences.shape[0], tokenized_sentences.shape[1], -1)\n",
    "print(f\"Embedded sentences shape: {embedded_sentences.shape}\")\n",
    "\n",
    "#add random noise to the embeddings\n",
    "perturbed_embeddings = embedded_sentences + torch.randn(embedded_sentences.shape)*0.0001\n",
    "\n",
    "batch_emb, batch_tokens  = project_embeddings(sample_embeddings = perturbed_embeddings,\n",
    "                       sample_tokens = torch.tensor(tokenized_sentences),\n",
    "                       vocab = flex_vocab,\n",
    "                       mask = torch.ones_like(tokenized_sentences)+torch.ones_like(tokenized_sentences),\n",
    "                       method = 'strict')\n",
    "\n",
    "print('embedding_matrix:', flex_vocab.embedding_matrix)\n",
    "print(\"Batch tokens:\", batch_tokens)\n",
    "print(\"Batch embeddings:\", batch_emb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
